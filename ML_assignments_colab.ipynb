{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df082270",
   "metadata": {},
   "source": [
    "\n",
    "# Tema: Regresie polinomială, Regresie logistică și Naive Bayes\n",
    "\n",
    "Acest notebook conține rezolvările (cod + grafice + metrici) pentru toate cele trei probleme cerute de tine: **regresie polinomială** (fermier & fertilizator), **regresie logistică** (boală cardiacă) și **clasificator Naive Bayes** (spam).\n",
    "\n",
    "Fiecare secțiune are: împărțirea datelor, antrenare model, metrici (train/test), vizualizări și concluzii. Pune notebook-ul în Google Colab: `File > Upload notebook` sau deschide-l din Drive după ce-l încarci.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Librării folosite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 1) Regresie polinomială\n",
    "# ---------------------------\n",
    "X = np.array([10,20,30,40,50,60,70,80,90,100,110,120,130,140,150]).reshape(-1,1)\n",
    "y = np.array([2.1,2.8,3.6,4.5,5.2,5.8,6.2,6.4,6.5,6.4,6.2,5.9,5.4,4.8,4.0])\n",
    "\n",
    "# Împărțire: primele 12 puncte = antrenare, ultimele 3 = testare\n",
    "X_train, X_test = X[:12], X[12:15]\n",
    "y_train, y_test = y[:12], y[12:15]\n",
    "\n",
    "results = {}\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X, y, label='Date (observații)', color='black')\n",
    "\n",
    "# evaluare pentru gradele 1..4\n",
    "xs_dense = np.linspace(0,170,500).reshape(-1,1)\n",
    "for deg in [1,2,3,4]:\n",
    "    poly = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    Xtr_poly = poly.fit_transform(X_train)\n",
    "    Xte_poly = poly.transform(X_test)\n",
    "    Xdense_poly = poly.transform(xs_dense)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(Xtr_poly, y_train)\n",
    "    # predicții\n",
    "    ytr_pred = lr.predict(Xtr_poly)\n",
    "    yte_pred = lr.predict(Xte_poly)\n",
    "    ydense = lr.predict(Xdense_poly)\n",
    "    # metrici\n",
    "    metrics = {}\n",
    "    metrics['MAE_train'] = mean_absolute_error(y_train, ytr_pred)\n",
    "    metrics['MSE_train'] = mean_squared_error(y_train, ytr_pred)\n",
    "    metrics['RMSE_train'] = np.sqrt(metrics['MSE_train'])\n",
    "    metrics['R2_train'] = r2_score(y_train, ytr_pred)\n",
    "    metrics['MAE_test'] = mean_absolute_error(y_test, yte_pred)\n",
    "    metrics['MSE_test'] = mean_squared_error(y_test, yte_pred)\n",
    "    metrics['RMSE_test'] = np.sqrt(metrics['MSE_test'])\n",
    "    metrics['R2_test'] = r2_score(y_test, yte_pred)\n",
    "    # cantitate optima (maxim predicted)\n",
    "    opt_idx = np.argmax(ydense)\n",
    "    opt_amount = xs_dense[opt_idx,0]\n",
    "    opt_value = ydense[opt_idx]\n",
    "    metrics['opt_amount'] = float(opt_amount)\n",
    "    metrics['opt_value'] = float(opt_value)\n",
    "    results[deg] = metrics\n",
    "    # plot\n",
    "    plt.plot(xs_dense, ydense, label=f'Deg {deg}')\n",
    "    \n",
    "# plot train/test markers with different markers\n",
    "plt.scatter(X_train, y_train, label='Train', marker='o', s=60)\n",
    "plt.scatter(X_test, y_test, label='Test', marker='X', s=80)\n",
    "plt.xlabel('Fertilizator (kg/ha)')\n",
    "plt.ylabel('Randament (tone/ha)')\n",
    "plt.legend()\n",
    "plt.title('Modele polinomiale (grad 1..4) - predicții')\n",
    "plt.show()\n",
    "\n",
    "# afișare metrici\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print('Metrici pentru modelele polinomiale (1..4):')\n",
    "pp.pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 2) Regresie logistică\n",
    "# ---------------------------\n",
    "age = np.array([25,30,35,40,45,50,52,55,58,60,62,65,68,70,72,75,78,80])\n",
    "chol = np.array([180,190,195,200,210,220,235,240,250,255,265,270,280,285,295,300,310,320])\n",
    "y_card = np.array([0,0,0,0,0,0,1,0,1,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "X = np.vstack([age, chol]).T\n",
    "# split: first 14 train, last 4 test\n",
    "X_train, X_test = X[:14], X[14:18]\n",
    "y_train, y_test = y_card[:14], y_card[14:18]\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xtr_s = scaler.transform(X_train)\n",
    "Xte_s = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(Xtr_s, y_train)\n",
    "\n",
    "# predicții și probabilități\n",
    "ytr_pred = clf.predict(Xtr_s)\n",
    "yte_pred = clf.predict(Xte_s)\n",
    "ytr_prob = clf.predict_proba(Xtr_s)[:,1]\n",
    "yte_prob = clf.predict_proba(Xte_s)[:,1]\n",
    "\n",
    "# metrici\n",
    "def print_log_metrics(y_true, y_pred, y_prob, name='set'):\n",
    "    print(f'--- Metrics for {name} ---')\n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    print('Precision:', precision_score(y_true, y_pred, zero_division=0))\n",
    "    print('Recall:', recall_score(y_true, y_pred, zero_division=0))\n",
    "    print('F1:', f1_score(y_true, y_pred, zero_division=0))\n",
    "    try:\n",
    "        print('ROC AUC:', roc_auc_score(y_true, y_prob))\n",
    "    except Exception as e:\n",
    "        print('ROC AUC: N/A', e)\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "print_log_metrics(y_train, ytr_pred, ytr_prob, 'train')\n",
    "print_log_metrics(y_test, yte_pred, yte_prob, 'test')\n",
    "\n",
    "# Vizualizare funcție decizie (probabilitate) pe grid - 2D\n",
    "xx, yy = np.meshgrid(np.linspace(age.min()-5, age.max()+5, 200),\n",
    "                     np.linspace(chol.min()-10, chol.max()+10, 200))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "grid_s = scaler.transform(grid)\n",
    "probs = clf.predict_proba(grid_s)[:,1].reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "cs = plt.contourf(xx, yy, probs, levels=20, cmap='RdYlBu', alpha=0.8)\n",
    "plt.colorbar(cs, label='Probabilitate boală')\n",
    "plt.scatter(X[:,0], X[:,1], c=y_card, edgecolor='k')\n",
    "plt.xlabel('Vârstă')\n",
    "plt.ylabel('Colesterol (mg/dL)')\n",
    "plt.title('Funcția de decizie (probabilitate) - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# predictie pentru persoana de 55 ani si colesterol 260 mg/dL\n",
    "sample = np.array([[55, 260]])\n",
    "sample_s = scaler.transform(sample)\n",
    "prob_sample = clf.predict_proba(sample_s)[:,1][0]\n",
    "print(f'Probabilitatea prezisă de boală pentru (55 ani, colesterol 260) = {prob_sample:.4f}')\n",
    "\n",
    "# importanța caracteristicilor: coeficienți\n",
    "coef = clf.coef_[0]\n",
    "feat_names = ['age','cholesterol']\n",
    "print('\\nCoeficienți (logit):')\n",
    "for n,c in zip(feat_names, coef):\n",
    "    print(f'  {n}: {c:.4f} (impact asupra log-odds, semn -> direcție)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 3) Naive Bayes (Spam)\n",
    "# ---------------------------\n",
    "# Construim DataFrame manual\n",
    "data = {\n",
    "    'Free': ['Da','Da','Nu','Da','Nu','Da','Nu','Nu','Da','Nu','Da','Nu','Da','Nu','Nu','Da','Nu','Da','Nu','Nu'],\n",
    "    'Money': ['Da','Da','Nu','Nu','Nu','Da','Da','Nu','Da','Nu','Nu','Nu','Da','Da','Nu','Da','Nu','Nu','Nu','Nu'],\n",
    "    'Winner': ['Da','Nu','Nu','Da','Nu','Da','Nu','Nu','Da','Da','Nu','Nu','Da','Da','Nu','Nu','Nu','Da','Da','Nu'],\n",
    "    'Link': ['Da','Da','Nu','Da','Da','Da','Da','Nu','Nu','Nu','Da','Nu','Da','Da','Da','Da','Nu','Da','Nu','Nu'],\n",
    "    'Spam': [1,1,0,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,1,0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "# codificare Da/Nu -> 1/0\n",
    "df_bin = df.replace({'Da':1,'Nu':0})\n",
    "X = df_bin[['Free','Money','Winner','Link']].values\n",
    "y = df_bin['Spam'].values\n",
    "\n",
    "# split: primele 16 train, ultimele 4 test\n",
    "X_train, X_test = X[:16], X[16:20]\n",
    "y_train, y_test = y[:16], y[16:20]\n",
    "\n",
    "# 2) Calculare manual priors (train)\n",
    "p_spam = y_train.mean()\n",
    "p_notspam = 1 - p_spam\n",
    "print('P(Spam) =', p_spam, ' P(NotSpam)=', p_notspam)\n",
    "\n",
    "# 3) probabilitati conditionale P(feature|class) (fara Laplace)\n",
    "def cond_probs(X, y):\n",
    "    # returns P(feature=1|class=1) and P(feature=1|class=0)\n",
    "    probs = {}\n",
    "    for i,feat in enumerate(['Free','Money','Winner','Link']):\n",
    "        p1 = X[y==1,i].mean() if np.sum(y==1)>0 else 0\n",
    "        p0 = X[y==0,i].mean() if np.sum(y==0)>0 else 0\n",
    "        probs[feat] = {'P(feature=1|Spam)=%.3f'%p1: p1, 'P(feature=1|NotSpam)=%.3f'%p0: p0}\n",
    "    return probs\n",
    "\n",
    "probs_no_laplace = cond_probs(X_train, y_train)\n",
    "print('\\nProb. condiționale (fără Laplace):')\n",
    "for k,v in probs_no_laplace.items():\n",
    "    print(k, v)\n",
    "\n",
    "# 4) Clasificare manuală pentru nou email: Free=Da,Money=Nu,Winner=Da,Link=Da\n",
    "new = np.array([1,0,1,1])\n",
    "# Calcul manual: P(Spam|x) ∝ P(Spam) * Π P(feature_i|Spam) (if feature=1 use p, if 0 use 1-p)\n",
    "def manual_nb_predict(x, p_spam, p_notspam, X_train, y_train, laplace=False, alpha=1):\n",
    "    # compute conditional probabilities with optional Laplace smoothing\n",
    "    cond = {}\n",
    "    n_spam = np.sum(y_train==1)\n",
    "    n_not = np.sum(y_train==0)\n",
    "    for i,feat in enumerate(['Free','Money','Winner','Link']):\n",
    "        # counts\n",
    "        count_spam = np.sum(X_train[y_train==1,i]==1)\n",
    "        count_not = np.sum(X_train[y_train==0,i]==1)\n",
    "        if laplace:\n",
    "            p_f_given_spam = (count_spam + alpha) / (n_spam + 2*alpha)\n",
    "            p_f_given_not = (count_not + alpha) / (n_not + 2*alpha)\n",
    "        else:\n",
    "            p_f_given_spam = count_spam / n_spam if n_spam>0 else 0\n",
    "            p_f_given_not = count_not / n_not if n_not>0 else 0\n",
    "        cond[feat] = (p_f_given_spam, p_f_given_not)\n",
    "    # compute likelihoods\n",
    "    lik_spam = p_spam\n",
    "    lik_not = p_notspam\n",
    "    for i,val in enumerate(x):\n",
    "        p1_spam, p1_not = cond[['Free','Money','Winner','Link'][i]]\n",
    "        if val==1:\n",
    "            lik_spam *= p1_spam\n",
    "            lik_not *= p1_not\n",
    "        else:\n",
    "            lik_spam *= (1-p1_spam)\n",
    "            lik_not *= (1-p1_not)\n",
    "    # normalize\n",
    "    total = lik_spam + lik_not\n",
    "    prob_spam = lik_spam / total if total>0 else 0\n",
    "    return prob_spam, cond\n",
    "\n",
    "prob_manual, conds = manual_nb_predict(new, p_spam, p_notspam, X_train, y_train, laplace=False)\n",
    "print('\\nProbabilitate manuală (fără Laplace) pentru noul email =', prob_manual)\n",
    "print('\\nCondiționale folosite:')\n",
    "for k,v in conds.items():\n",
    "    print(k, 'P(1|Spam)=%.3f, P(1|Not)=%.3f' % v)\n",
    "\n",
    "# 5) Antrenare model BernoulliNB și comparare\n",
    "clf = BernoulliNB(alpha=1.0)  # Laplace smoothing by default alpha=1\n",
    "clf.fit(X_train, y_train)\n",
    "print('\\nBernoulliNB (with Laplace alpha=1) - trained')\n",
    "print('Pred nou (prob spam) =', clf.predict_proba([new])[0,1])\n",
    "\n",
    "# 6) Matrice confuzie și metrici train/test\n",
    "for name,(Xt,yt) in [('train',(X_train,y_train)),('test',(X_test,y_test))]:\n",
    "    pred = clf.predict(Xt)\n",
    "    print(f'\\n--- Metrics {name} ---')\n",
    "    print('Confusion matrix:\\n', confusion_matrix(yt, pred))\n",
    "    print('Accuracy:', accuracy_score(yt,pred))\n",
    "    print('Precision:', precision_score(yt,pred, zero_division=0))\n",
    "    print('Recall:', recall_score(yt,pred, zero_division=0))\n",
    "    print('F1:', f1_score(yt,pred, zero_division=0))\n",
    "\n",
    "# 7) Efectul Laplace: comparam probabilitățile manual cu/ fără Laplace\n",
    "prob_manual_lap, conds_lap = manual_nb_predict(new, p_spam, p_notspam, X_train, y_train, laplace=True, alpha=1)\n",
    "print('\\nProb manual (cu Laplace alpha=1) =', prob_manual_lap)\n",
    "\n",
    "# 8) Importanța caracteristici: log prob ratio (BernoulliNB) - features cu cel mai mare uplift pentru spam\n",
    "# folosim log(P(feature=1|Spam)/P(feature=1|NotSpam))\n",
    "feature_importance = {}\n",
    "for i,feat in enumerate(['Free','Money','Winner','Link']):\n",
    "    p1_spam = clf.feature_log_prob_[1,i]  # log P(x_i=1 | class=1)\n",
    "    p1_not = clf.feature_log_prob_[0,i]   # log P(x_i=1 | class=0)\n",
    "    # compute difference of log-probs\n",
    "    feature_importance[feat] = float(p1_spam - p1_not)\n",
    "print('\\nFeature importance (log-prob difference) - higher means more indicative for Spam:')\n",
    "for k,v in sorted(feature_importance.items(), key=lambda x:-x[1]):\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbab117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salvăm notebook-ul în /mnt/data\n",
    "from pathlib import Path\n",
    "fname = '/mnt/data/ML_assignments_colab.ipynb'\n",
    "import nbformat\n",
    "nbformat.write(nb, fname)\n",
    "print('Notebook salvat la:', fname)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
